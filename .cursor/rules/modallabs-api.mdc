---
title: Modal Labs - Complete API Use Guide
description: A comprehensive guide for integrating and operating with Modal Labs for high-performance serverless computing, with focus on ML/AI workloads and batch processing.
---

```mermaid
flowchart TD
    A[Input Source] --> B[Modal Stub]
    B --> C1[GPU Functions]
    B --> C2[CPU Functions]
    B --> C3[Memory-Optimized]
    C1 --> D1[ML Processing]
    C1 --> D2[Transcription]
    C2 --> D3[NLP Tasks]
    C2 --> D4[Batch Jobs]
    C3 --> D5[Large Data Processing]
    D1 --> E[Results]
    D2 --> E
    D3 --> E
    D4 --> E
    D5 --> E
```

## üì¶ Overview
Modal Labs provides a powerful serverless computing platform optimized for:
- ML/AI workloads with GPU support
- Batch processing with automatic scaling
- High-memory computing tasks
- Long-running background jobs
- Real-time API endpoints

Key features:
- Automatic container management
- GPU instance provisioning
- Memory optimization
- Function-level scaling
- Built-in monitoring
- Cost optimization

## ‚úÖ Setup & Configuration

### Basic Setup
```bash
pip install modal
modal token new
```

### Environment Configuration
```python
import os
import modal

# Load environment variables
modal.Secret({
    "ASSEMBLYAI_API_KEY": os.environ["ASSEMBLYAI_API_KEY"],
    "OPENAI_API_KEY": os.environ["OPENAI_API_KEY"]
})
```

## üéØ Core Concepts

### Stub Definition
```python
import modal

stub = modal.Stub("meeting-analyzer")

# Define container image
image = modal.Image.debian_slim().pip_install([
    "assemblyai",
    "transformers",
    "torch",
    "numpy"
])
```

### Function Types

1. **GPU Functions**
```python
@stub.function(
    gpu="A10G",
    memory=16384,
    timeout=3600,
    image=image
)
def process_ml_task():
    pass
```

2. **CPU Functions**
```python
@stub.function(
    cpu=2,
    memory=4096,
    timeout=1800,
    image=image
)
def process_nlp_task():
    pass
```

3. **Memory-Optimized Functions**
```python
@stub.function(
    memory=32768,
    timeout=7200,
    image=image
)
def process_large_data():
    pass
```

## üö¶ Execution & Infrastructure Integration

### Local Development Execution
```bash
# Direct execution of a function
modal run ./src/modal_functions/transcription.py --audio_url "https://example.com/audio.mp3"

# Running with specific parameters
modal run -m src.modal_functions.transcription --function process_audio --args '{"url": "https://example.com/audio.mp3"}'

# Development server for API endpoints
modal serve ./src/modal_functions/api.py
```

### Production Deployment & Execution
```python
# src/modal_functions/transcription.py
import modal

stub = modal.Stub("meeting-analyzer")

@stub.function(
    gpu="A10G",
    memory=16384,
    timeout=3600,
    image=image
)
def process_audio(url: str):
    # Implementation
    pass

# Deployment endpoint
@stub.function()
@modal.web_endpoint(method="POST")
async def process_meeting():
    # Implementation
    pass

# To deploy:
# modal deploy ./src/modal_functions/transcription.py
```

### Infrastructure Integration

```mermaid
flowchart TD
    A[Next.js Frontend] --> B[Edge Functions]
    B --> C[Modal Functions]
    C --> D1[AssemblyAI Processing]
    C --> D2[NLP Processing]
    C --> D3[Batch Processing]
    D1 --> E[Results]
    D2 --> E
    D3 --> E
    E --> F[Supabase Storage]
```

#### Execution Patterns

1. **Direct API Integration**
```typescript
// Frontend API call
async function processMeeting(audioUrl: string) {
    const response = await fetch('/api/process-meeting', {
        method: 'POST',
        body: JSON.stringify({ audioUrl })
    });
    return await response.json();
}
```

2. **Background Job Processing**
```python
# Modal function
@stub.function(
    gpu="A10G",
    memory=16384,
    timeout=3600
)
async def process_meeting_background(meeting_id: str):
    # 1. Fetch meeting data
    # 2. Process with AssemblyAI
    # 3. Run NLP analysis
    # 4. Store results
    pass

# Edge function trigger
async def trigger_processing(meeting_id: str):
    process_meeting_background.spawn(meeting_id)
```

3. **Batch Processing Integration**
```python
@stub.function(
    cpu=4,
    memory=8192,
    timeout=7200
)
def process_meetings_batch(meeting_ids: List[str]):
    return modal.map(process_meeting_background, meeting_ids, order=True)

# Edge function trigger
async def trigger_batch_processing(meeting_ids: List[str]):
    process_meetings_batch.spawn(meeting_ids)
```

#### Directory Structure
```
src/
‚îú‚îÄ‚îÄ modal_functions/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py          # Configuration and environment setup
‚îÇ   ‚îú‚îÄ‚îÄ transcription.py   # AssemblyAI integration
‚îÇ   ‚îú‚îÄ‚îÄ nlp.py            # NLP processing functions
‚îÇ   ‚îú‚îÄ‚îÄ batch.py          # Batch processing handlers
‚îÇ   ‚îî‚îÄ‚îÄ api.py            # Web endpoints
‚îú‚îÄ‚îÄ edge_functions/
‚îÇ   ‚îî‚îÄ‚îÄ process-meeting.ts # Edge function handler
‚îî‚îÄ‚îÄ providers/
    ‚îú‚îÄ‚îÄ modal.ts          # Modal client integration
    ‚îî‚îÄ‚îÄ types.ts          # Shared types
```

#### Environment Configuration
```bash
# .env.production
MODAL_TOKEN_ID=prod_token_id
MODAL_TOKEN_SECRET=prod_token_secret
ASSEMBLYAI_API_KEY=your_api_key
```

#### Deployment Flow
1. **Development**:
   ```bash
   # Start development server
   modal serve ./src/modal_functions/api.py
   
   # Test specific function
   modal run ./src/modal_functions/transcription.py --function process_audio
   ```

2. **Staging**:
   ```bash
   # Deploy to staging environment
   modal deploy --env staging ./src/modal_functions/api.py
   
   # Verify deployment
   modal status --env staging
   ```

3. **Production**:
   ```bash
   # Deploy to production
   modal deploy --env production ./src/modal_functions/api.py
   
   # Monitor deployment
   modal logs --env production
   ```

#### Health Checks & Monitoring
```python
@stub.function()
@modal.web_endpoint(method="GET")
async def healthcheck():
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

# Monitoring endpoint
@stub.function()
@modal.web_endpoint(method="GET")
async def metrics():
    return {
        "gpu_utilization": modal.gpu.utilization(),
        "memory_usage": modal.memory.usage(),
        "active_functions": modal.functions.active()
    }
```

## üîÑ Integration Patterns

### Provider Pattern
```python
from abc import ABC, abstractmethod
from typing import Dict, Any

class ProcessingProvider(ABC):
    @abstractmethod
    async def initialize(self) -> None:
        pass
    
    @abstractmethod
    async def process(self, data: Dict[str, Any]) -> Dict[str, Any]:
        pass
    
    @abstractmethod
    async def cleanup(self) -> None:
        pass

@stub.cls(
    gpu="A10G",
    memory=16384,
    image=image
)
class TranscriptionProvider(ProcessingProvider):
    def __enter__(self):
        self.initialize()
        
    async def process(self, data: Dict[str, Any]) -> Dict[str, Any]:
        # Implementation
        pass
    
    def __exit__(self):
        self.cleanup()
```

### Batch Processing
```python
@stub.function(
    cpu=2,
    memory=4096,
    timeout=3600
)
def process_batch(items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    results = []
    for item in items:
        result = process_item.remote(item)
        results.append(result)
    return modal.gather(results)
```

## üéØ Practical Integration & Usage

### Integration Architecture

```mermaid
flowchart TD
    A[Next.js Frontend] --> B[Edge Function]
    B --> C[Modal Web Endpoint]
    C --> D[Modal Function]
    D --> E[Webhook Callback]
    E --> F[Edge Function]
    F --> G[Supabase]
    G --> H[Frontend Update]

    subgraph "Nossa Infraestrutura"
        A[Next.js Frontend]
        B[Edge Function]
        F[Edge Function/Webhook Handler]
        G[Supabase]
        H[Frontend Update]
    end

    subgraph "Modal Cloud"
        C[Modal Web Endpoint]
        D[Modal Function]
        E[Webhook Callback]
    end
```

### 1. Deploy das Fun√ß√µes Modal

```python
# src/modal_functions/api.py
import modal
from typing import Dict, Any

stub = modal.Stub("meeting-analyzer")

@stub.function(
    gpu="A10G",
    memory=16384,
    secret=modal.Secret({
        "ASSEMBLYAI_API_KEY": "your-key"
    })
)
async def process_audio(audio_url: str) -> Dict[str, Any]:
    result = await process_with_assemblyai(audio_url)
    return result

# Endpoint HTTP p√∫blico
@stub.function()
@modal.web_endpoint(method="POST")
async def process_meeting(audio_url: str):
    try:
        # Inicia processamento ass√≠ncrono
        job = await process_audio.spawn(audio_url)
        
        return {
            "status": "processing",
            "jobId": job.object_id,  # ID √∫nico do job
            "webhook_url": "/api/modal-webhook"  # URL para receber callbacks
        }
    except Exception as e:
        return {"status": "error", "error": str(e)}
```

### 2. Configura√ß√£o do Ambiente

```bash
# .env.local
NEXT_PUBLIC_MODAL_API_URL="https://your-modal-app.modal.run"  # URL gerada pelo Modal ap√≥s deploy
MODAL_WEBHOOK_SECRET="your-webhook-secret"  # Secreto para validar webhooks
```

### 3. Integra√ß√£o no Frontend (Next.js)

```typescript
// src/app/meetings/[id]/page.tsx
'use client';

import { useState } from 'react';
import { processAudio } from '@/lib/meetings';

export default function MeetingPage({ params }: { params: { id: string } }) {
    const [status, setStatus] = useState<string>('idle');
    
    const handleProcessAudio = async () => {
        try {
            setStatus('processing');
            
            // Inicia processamento
            const response = await processAudio(params.id);
            
            if (response.jobId) {
                // Atualiza UI e aguarda webhook
                setStatus('processing');
            }
        } catch (error) {
            setStatus('error');
            console.error('Processing error:', error);
        }
    };
    
    return (
        <div>
            <button 
                onClick={handleProcessAudio}
                disabled={status === 'processing'}
            >
                Process Audio
            </button>
            <div>Status: {status}</div>
        </div>
    );
}
```

### 4. Camada de Servi√ßo

```typescript
// src/lib/meetings.ts
import { createClient } from '@supabase/supabase-js';

const MODAL_API_URL = process.env.NEXT_PUBLIC_MODAL_API_URL;

export async function processAudio(meetingId: string) {
    // 1. Obt√©m URL do √°udio do Supabase
    const { data: meeting } = await supabase
        .from('meetings')
        .select('audio_url')
        .eq('id', meetingId)
        .single();
    
    if (!meeting?.audio_url) {
        throw new Error('Audio not found');
    }
    
    // 2. Chama endpoint Modal
    const response = await fetch(`${MODAL_API_URL}/process_meeting`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ audio_url: meeting.audio_url })
    });
    
    if (!response.ok) {
        throw new Error('Modal processing failed');
    }
    
    const { jobId } = await response.json();
    
    // 3. Atualiza status no banco
    await supabase
        .from('meetings')
        .update({ 
            processing_status: 'processing',
            modal_job_id: jobId
        })
        .eq('id', meetingId);
    
    return { jobId };
}
```

### 5. Webhook Handler

```typescript
// src/app/api/modal-webhook/route.ts
import { headers } from 'next/headers';
import { createClient } from '@supabase/supabase-js';

export async function POST(request: Request) {
    // 1. Valida webhook
    const headersList = headers();
    const signature = headersList.get('x-modal-signature');
    if (!validateModalWebhook(signature)) {
        return Response.json({ error: 'Invalid signature' }, { status: 401 });
    }
    
    const payload = await request.json();
    const { jobId, status, result } = payload;
    
    try {
        // 2. Atualiza banco de dados
        const { data: meeting } = await supabase
            .from('meetings')
            .update({
                processing_status: status,
                transcription: result?.transcription,
                analysis: result?.analysis
            })
            .eq('modal_job_id', jobId)
            .select()
            .single();
        
        // 3. Notifica frontend via Realtime
        if (meeting) {
            await supabase
                .from('meeting_updates')
                .insert({
                    meeting_id: meeting.id,
                    status,
                    timestamp: new Date().toISOString()
                });
        }
        
        return Response.json({ success: true });
    } catch (error) {
        console.error('Webhook processing error:', error);
        return Response.json({ error: 'Processing failed' }, { status: 500 });
    }
}
```

### 6. Monitoramento e Status

```typescript
// src/lib/modal-status.ts
export async function checkModalJobStatus(jobId: string) {
    const response = await fetch(`${MODAL_API_URL}/jobs/${jobId}`);
    if (!response.ok) {
        throw new Error('Failed to check job status');
    }
    return response.json();
}

// Componente de status
export function JobStatus({ jobId }: { jobId: string }) {
    const [status, setStatus] = useState('');
    
    useEffect(() => {
        const checkStatus = async () => {
            try {
                const result = await checkModalJobStatus(jobId);
                setStatus(result.status);
            } catch (error) {
                console.error('Status check failed:', error);
            }
        };
        
        // Verifica status a cada 30 segundos
        const interval = setInterval(checkStatus, 30000);
        return () => clearInterval(interval);
    }, [jobId]);
    
    return <div>Job Status: {status}</div>;
}
```

### 7. Fluxo de Deploy

```yaml
# .github/workflows/modal-deploy.yml
name: Deploy Modal Functions
on:
  push:
    branches: [main]
    paths:
      - 'src/modal_functions/**'

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.11'
      
      - name: Install Modal
        run: pip install modal
      
      - name: Configure Modal
        run: |
          echo "${{ secrets.MODAL_TOKEN_ID }}" > ~/.modal/token.id
          echo "${{ secrets.MODAL_TOKEN_SECRET }}" > ~/.modal/token.secret
      
      - name: Deploy Functions
        run: |
          cd src/modal_functions
          modal deploy api.py --env production
      
      - name: Update API URL
        run: |
          # Atualiza URL no .env.production
          MODAL_URL=$(modal endpoints list --json | jq -r '.[] | select(.name=="process_meeting") | .url')
          echo "NEXT_PUBLIC_MODAL_API_URL=$MODAL_URL" >> .env.production
```

### 8. Recupera√ß√£o de Erros

```typescript
// src/lib/modal-error-handling.ts
export class ModalProcessingError extends Error {
    constructor(
        message: string,
        public jobId?: string,
        public status?: string
    ) {
        super(message);
        this.name = 'ModalProcessingError';
    }
}

export async function handleModalError(error: ModalProcessingError, meetingId: string) {
    // 1. Registra erro
    await supabase
        .from('meeting_errors')
        .insert({
            meeting_id: meetingId,
            job_id: error.jobId,
            error_message: error.message,
            timestamp: new Date().toISOString()
        });
    
    // 2. Notifica administradores
    await notifyAdmins({
        type: 'modal_error',
        meetingId,
        error: error.message
    });
    
    // 3. Atualiza status
    await supabase
        .from('meetings')
        .update({ 
            processing_status: 'error',
            error_details: error.message
        })
        .eq('id', meetingId);
}
```

### 9. Uso Pr√°tico

1. **Iniciar Processamento**:
```typescript
// Em qualquer componente
const startProcessing = async (meetingId: string) => {
    try {
        const { jobId } = await processAudio(meetingId);
        // jobId pode ser usado para acompanhamento
    } catch (error) {
        await handleModalError(error, meetingId);
    }
};
```

2. **Acompanhar Progresso**:
```typescript
// Componente com Realtime
function MeetingProgress({ meetingId }: { meetingId: string }) {
    const [status, setStatus] = useState('');
    
    useEffect(() => {
        const subscription = supabase
            .channel('meeting_updates')
            .on(
                'postgres_changes',
                {
                    event: 'INSERT',
                    schema: 'public',
                    table: 'meeting_updates',
                    filter: `meeting_id=eq.${meetingId}`
                },
                (payload) => {
                    setStatus(payload.new.status);
                }
            )
            .subscribe();
            
        return () => {
            subscription.unsubscribe();
        };
    }, [meetingId]);
    
    return <div>Processing Status: {status}</div>;
}
```

## üéõÔ∏è Resource Management

### GPU Configuration
```python
GPU_CONFIGS = {
    "transcription": {
        "type": "A10G",
        "memory": 16384,
        "timeout": 3600
    },
    "ml_inference": {
        "type": "A100",
        "memory": 32768,
        "timeout": 7200
    }
}
```

### Memory Management
```python
@stub.function(
    memory=lambda input_size: min(input_size * 2, 32768),
    timeout=3600
)
def process_with_dynamic_memory(data: bytes) -> Dict[str, Any]:
    pass
```

## üîç Error Handling

### Retry Logic
```python
@stub.function(
    retries=3,
    backoff=modal.Backoff.exponential(initial=1)
)
def process_with_retries(data: Dict[str, Any]):
    try:
        return await process_data(data)
    except Exception as e:
        await notify_error(str(e))
        raise
```

### Checkpointing
```python
@stub.function(
    checkpoint=True,
    memory=16384
)
def long_running_task():
    checkpoint_state = {}
    # Implementation with checkpointing
    pass
```

## üìä Monitoring & Logging

### Function Metrics
```python
@stub.function(
    gpu="A10G",
    memory=16384
)
def monitored_process():
    with modal.metrics.timer("processing_time"):
        # Implementation
        pass
```

### Resource Usage
```python
@stub.function(
    gpu="A10G",
    memory=16384
)
def track_resources():
    modal.metrics.gauge(
        "gpu_memory_used",
        modal.gpu.memory_used()
    )
```

## üîí Security

### Secret Management
```python
secret = modal.Secret({
    "API_KEY": "your-api-key"
})

@stub.function(secret=secret)
def secure_process():
    key = os.environ["API_KEY"]
    # Implementation
```

### Network Isolation
```python
@stub.function(
    network_file_systems={"/data": volume},
    allow_network_access=["api.assemblyai.com"]
)
def isolated_process():
    pass
```

## üí° Best Practices

1. **Resource Optimization**
   - Use appropriate GPU types
   - Set memory limits correctly
   - Configure timeouts properly
   - Implement checkpointing for long tasks

2. **Error Handling**
   - Implement retries with backoff
   - Use checkpointing for recovery
   - Handle partial failures
   - Monitor resource usage

3. **Performance**
   - Batch similar operations
   - Reuse container images
   - Cache intermediate results
   - Use appropriate instance types

4. **Security**
   - Manage secrets properly
   - Restrict network access
   - Implement proper authentication
   - Monitor usage patterns

## üöÄ Deployment

### Development
```bash
modal serve modal_functions/transcription.py
```

### Production
```bash
modal deploy modal_functions/transcription.py
```

### Environment Management
```bash
modal environment create production
modal environment list
modal token new --env production
```

## üîß Common Use Cases

1. **Transcription Processing**
```python
@stub.function(
    gpu="A10G",
    memory=16384,
    timeout=3600
)
async def process_transcription(audio_url: str) -> Dict[str, Any]:
    provider = TranscriptionProvider()
    return await provider.process({"url": audio_url})
```

2. **NLP Tasks**
```python
@stub.function(
    cpu=2,
    memory=4096,
    timeout=1800
)
def process_nlp(text: str) -> Dict[str, Any]:
    # NLP processing implementation
    pass
```

3. **Batch Processing**
```python
@stub.function(
    cpu=4,
    memory=8192,
    timeout=7200
)
def process_batch(items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    return modal.map(process_item, items, order=True)
```

## ‚ö†Ô∏è Error Codes & Troubleshooting

Common error codes:
- `RESOURCE_EXCEEDED`: Memory or GPU limits exceeded
- `TIMEOUT`: Function execution timeout
- `NETWORK_ERROR`: Network connectivity issues
- `CONTAINER_ERROR`: Container startup or runtime errors

## üìà Performance Tips

1. **Container Optimization**
   - Use slim base images
   - Install only required dependencies
   - Cache layers effectively
   - Pre-warm containers when possible

2. **Resource Allocation**
   - Monitor GPU utilization
   - Track memory usage patterns
   - Adjust timeouts based on workload
   - Use appropriate instance types

3. **Cost Optimization**
   - Batch similar operations
   - Use spot instances when possible
   - Implement proper caching
   - Monitor resource usage

# General

For more detailed information, refer to:
- [Modal Labs Documentation](https://modal.com/docs)
- [API Reference](https://modal.com/docs/reference)
- [Examples Repository](https://github.com/modal-labs/modal-examples)

## üåê Web Endpoints & API Integration

### FastAPI Integration

Qualquer fun√ß√£o Modal pode ser exposta como um endpoint HTTP usando o decorador `@modal.fastapi_endpoint()`:

```python
# src/modal_functions/api.py
import modal
from fastapi import FastAPI, Request
from typing import Dict, Any

stub = modal.Stub("meeting-analyzer")
image = modal.Image.debian_slim().pip_install("fastapi[standard]")

# Endpoint simples
@stub.function(image=image)
@modal.fastapi_endpoint()
def healthcheck():
    return {"status": "healthy"}

# Endpoint com par√¢metros
@stub.function(image=image)
@modal.fastapi_endpoint()
def process_audio(audio_url: str):
    return {"status": "processing", "url": audio_url}

# Endpoint POST com corpo JSON
@stub.function(image=image)
@modal.fastapi_endpoint(method="POST")
def process_meeting(request_data: Dict[str, Any]):
    return {
        "status": "processing",
        "meeting_id": request_data["meeting_id"]
    }

# Endpoint com autentica√ß√£o
@stub.function(
    image=image,
    secrets=[modal.Secret.from_name("api-auth-token")]
)
@modal.fastapi_endpoint()
async def secure_endpoint(request: Request):
    token = request.headers.get("Authorization")
    if token != f"Bearer {os.environ['AUTH_TOKEN']}":
        raise HTTPException(
            status_code=401,
            detail="Invalid token"
        )
    return {"status": "authenticated"}
```

### URLs dos Endpoints

Ap√≥s o deploy, cada fun√ß√£o decorada com `@modal.fastapi_endpoint()` recebe uma URL √∫nica:

```bash
# Development
modal serve ./src/modal_functions/api.py
# Output: https://your-org--app-name-function-name-dev.modal.run

# Production
modal deploy ./src/modal_functions/api.py
# Output: https://your-org--app-name-function-name.modal.run
```

### Padr√µes de Uso

1. **Endpoint S√≠ncrono**:
```python
@stub.function(image=image)
@modal.fastapi_endpoint(method="POST")
def sync_process(data: Dict[str, Any]):
    result = process_data(data)
    return {"result": result}
```

2. **Endpoint Ass√≠ncrono com Job**:
```python
@stub.function(image=image)
@modal.fastapi_endpoint(method="POST")
async def async_process(data: Dict[str, Any]):
    # Inicia job em background
    job = process_data.spawn(data)
    return {
        "job_id": job.object_id,
        "status": "processing"
    }
```

3. **Endpoint com Valida√ß√£o**:
```python
from pydantic import BaseModel

class AudioRequest(BaseModel):
    url: str
    language: str = "en"
    model: str = "base"

@stub.function(image=image)
@modal.fastapi_endpoint(method="POST")
def process_audio(request: AudioRequest):
    return {
        "status": "processing",
        "config": request.dict()
    }
```

### Integra√ß√£o com Frontend

```typescript
// src/lib/modal-api.ts
export async function callModalEndpoint(endpoint: string, data: any) {
    const MODAL_BASE_URL = process.env.NEXT_PUBLIC_MODAL_API_URL;
    
    const response = await fetch(`${MODAL_BASE_URL}/${endpoint}`, {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${process.env.MODAL_API_TOKEN}`
        },
        body: JSON.stringify(data)
    });

    if (!response.ok) {
        throw new Error(`Modal API error: ${response.statusText}`);
    }

    return response.json();
}

// Uso no componente
const processAudio = async (audioUrl: string) => {
    try {
        const result = await callModalEndpoint('process_audio', {
            url: audioUrl,
            language: 'en'
        });
        return result;
    } catch (error) {
        console.error('Modal API error:', error);
        throw error;
    }
};
```

### Considera√ß√µes de Performance

1. **Cold Start**:
- Primeira chamada pode levar alguns segundos
- Container fica warm por um per√≠odo ap√≥s uso
- Use `@modal.concurrent` para m√∫ltiplas requisi√ß√µes no mesmo container

2. **Scaling**:
```python
@stub.function(image=image)
@modal.concurrent(max_inputs=1000)  # Permite at√© 1000 requisi√ß√µes simult√¢neas
@modal.fastapi_endpoint()
def scalable_endpoint():
    return {"status": "processing"}
```

3. **Timeouts**:
```python
@stub.function(
    image=image,
    timeout=300  # 5 minutos
)
@modal.fastapi_endpoint()
def long_running_endpoint():
    # Processamento longo
    pass
```

### Monitoramento de Endpoints

```python
@stub.function(image=image)
@modal.fastapi_endpoint()
def metrics():
    return {
        "requests": modal.metrics.counter("endpoint_requests"),
        "latency": modal.metrics.histogram("endpoint_latency"),
        "errors": modal.metrics.counter("endpoint_errors")
    }
```

### Seguran√ßa dos Endpoints

1. **Autentica√ß√£o via Token**:
```python
@stub.function(
    image=image,
    secrets=[modal.Secret.from_name("api-keys")]
)
@modal.fastapi_endpoint()
def secure_endpoint(request: Request):
    validate_auth_token(request.headers.get("Authorization"))
    return {"status": "authenticated"}
```

2. **Rate Limiting**:
```python
from fastapi import HTTPException

@stub.function(image=image)
@modal.fastapi_endpoint()
def rate_limited_endpoint(request: Request):
    if not check_rate_limit(request.client.host):
        raise HTTPException(
            status_code=429,
            detail="Too many requests"
        )
    return {"status": "ok"}
``` 